{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PreProcessing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YM7XHQJVwtmy"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Audio\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import librosa\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db_root = '.../Audio'   # add your own database directory path"
      ],
      "metadata": {
        "id": "k2ZghQ6Mw4MG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class log_mel_spec_builder:\n",
        "    def __init__(self, db_root, sr, n_fft, hop_length, n_mels):\n",
        "        self.db_root = db_root\n",
        "        self.sr = sr\n",
        "        self.n_fft = n_fft\n",
        "        self.hop_length = hop_length\n",
        "        self.n_mels = n_mels\n",
        "        self.all_audio_root = db_root + '/samples'\n",
        "        self.all_audio_files = glob.glob(self.all_audio_root + \"/*.*\")\n",
        "        self.logmel_saver_path = os.path.join(db_root, 'melspec_npy')\n",
        "\n",
        "    \n",
        "    def x_to_log_mel_spec(self, samples):\n",
        "        samples_mel_spec = librosa.feature.melspectrogram(samples,sr=self.sr,n_fft=self.n_fft,hop_length=self.hop_length,n_mels=self.n_mels)\n",
        "        samples_log_mel_spec = librosa.power_to_db(samples_mel_spec)   # create log-melspectogram of audio\n",
        "        return samples_log_mel_spec\n",
        "\n",
        "\n",
        "\n",
        "    def samples_to_logmel_converter(self):\n",
        "        audio_samples = []\n",
        "        count = 0\n",
        "        for audio in self.all_audio_files:\n",
        "            audio_name = re.findall('[0-9]+', audio)[0]\n",
        "            samples,sr = librosa.load(audio,sr=self.sr)\n",
        "\n",
        "            if samples.shape[0]<(sr*10):        # append zeros if clip duration is less than 10 seconds\n",
        "                appended_zeros = np.zeros(((sr*10)-samples.shape[0],))\n",
        "                samples = np.append(samples,appended_zeros,axis=0)\n",
        "            if samples.shape[0]>(sr*10):\n",
        "                splitted_samples = np.split(samples,[sr*10])        # crop to 10 sec if clip length is larger\n",
        "                samples = splitted_samples[0]\n",
        "\n",
        "            samples_log_mel_spec = self.x_to_log_mel_spec(samples)\n",
        "            samples_log_mel_spec = np.stack(samples_log_mel_spec)\n",
        "            audio_samples.append(samples_log_mel_spec)\n",
        "            count+=1\n",
        "            print(\"count: {}, audio-file: {}.wav\".format(count, audio_name))\n",
        "        audio_samples = np.stack(audio_samples,axis=0)\n",
        "        np.save(self.logmel_saver_path, audio_samples)    # saving all log-melspectogram in npy files\n",
        "        return audio_samples\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "YD_lAtGxw86t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotSpec(x):\n",
        "    plt.imshow(x)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "_HaXFPTTxA8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class audio_tasks_encoder:\n",
        "    def __init__(self, db_root, no_of_frames):\n",
        "        self.db_root = db_root\n",
        "        self.audio_hard_timestamp = pd.read_csv(db_root + '/meta.csv', sep='\\t')\n",
        "        self.audio_frame_label_path = os.path.join(db_root,'audio_frame_label')\n",
        "        self.no_of_frames = no_of_frames\n",
        "        self.audio_tag_path = os.path.join(self.db_root, 'audio_tag')\n",
        "\n",
        "\n",
        "    def one_hot_encoding(self):\n",
        "        integer_labeling = {key:value for (value,key) in enumerate(sorted(self.audio_hard_timestamp.event_label.unique()))}        # labeling the events as 0 to N\n",
        "        one_hot_encoded_labels = tf.keras.utils.to_categorical([i for i in integer_labeling.values()],num_classes=len(integer_labeling))        # one hot encoding\n",
        "\n",
        "        return integer_labeling, one_hot_encoded_labels\n",
        "\n",
        "\n",
        "    def framelevel_label_ground_truth(self):\n",
        "        integer_labeling, one_hot_encoded_labels = self.one_hot_encoding()\n",
        "        '''\n",
        "        from timestamp to frame convert:\n",
        "        hoplength of 512 at 16000 Hz sampling rate corresponds to 20 ms approx.\n",
        "        And window length is 1024.\n",
        "        Hence frame_no = ((timestamp * 1000) + 20)/20\n",
        "        '''\n",
        "        self.audio_hard_timestamp[['starting_time_frame','stopping_time_frame']] = (((self.audio_hard_timestamp[['onset','offset']]*1000)+20)/20).apply(np.ceil).astype(np.int64)      \n",
        "        audio_filenames = self.audio_hard_timestamp.filename.unique().tolist()\n",
        "        no_of_classes = len(list(self.audio_hard_timestamp.event_label.unique()))\n",
        "        self.audio_hard_timestamp = self.audio_hard_timestamp.set_index(keys=['filename','event_label'])\n",
        "        framewise_encoded_labels = []\n",
        "        for file in audio_filenames:\n",
        "            specific_clip_label_chunk = self.audio_hard_timestamp.xs(file,level=0,drop_level=True).loc[:,['starting_time_frame','stopping_time_frame']]\n",
        "            frame_labels = np.zeros((self.no_of_frames, no_of_classes))\n",
        "            for row in specific_clip_label_chunk.iterrows():\n",
        "                event_label = row[0]\n",
        "                event_starting_time = row[1]['starting_time_frame']\n",
        "                event_stopping_time = row[1]['stopping_time_frame']\n",
        "                event_encoded = one_hot_encoded_labels[integer_labeling[event_label]]\n",
        "                frame_labels[(event_starting_time-1):(event_stopping_time-1),:]+=event_encoded\n",
        "            framewise_encoded_labels.append(frame_labels)\n",
        "        np.save(self.audio_frame_label_path, framewise_encoded_labels)\n",
        "        return np.ascontiguousarray(framewise_encoded_labels)\n",
        "\n",
        "\n",
        "    def audio_tag_ground_truth(self):\n",
        "        integer_labeling, one_hot_encoded_labels = self.one_hot_encoding()\n",
        "        audio_filenames = self.audio_hard_timestamp.filename.unique().tolist()\n",
        "        self.audio_hard_timestamp = self.audio_hard_timestamp.set_index(keys=['filename', 'event_label'])\n",
        "        cliplevel_encoded_labels = []\n",
        "        for file in audio_filenames:\n",
        "            specific_clip_label_chunk_unique_labels = self.audio_hard_timestamp.xs(file,level=0).reset_index().event_label.unique().tolist()\n",
        "            cliplevel_labels = np.zeros((len(integer_labeling)))\n",
        "            for label in specific_clip_label_chunk_unique_labels:\n",
        "                cliplevel_labels[integer_labeling[label]]+=1\n",
        "            cliplevel_encoded_labels.append(cliplevel_labels)\n",
        "        \n",
        "        np.save(self.audio_tag_path, np.stack(cliplevel_encoded_labels))\n",
        "        return np.ascontiguousarray(cliplevel_encoded_labels)\n",
        "    \n"
      ],
      "metadata": {
        "id": "l9Ow976DxKEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fABrH8tExOFe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}